{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804f4268",
   "metadata": {},
   "source": [
    "# Aula 3 — Primeiro contato com PySpark\n",
    "\n",
    "Neste notebook, você vai executar seus primeiros comandos em PySpark.\n",
    "\n",
    "Você vai:\n",
    "- criar dados com `spark.range()`\n",
    "- ver que isso gera um DataFrame\n",
    "- visualizar os dados com `show()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446516b",
   "metadata": {},
   "source": [
    "## Observação importante (ambiente local)\n",
    "\n",
    "Para o Spark funcionar no computador, o **Java precisa estar instalado**.\n",
    "Recomendação: **Java 17 ou superior**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e09e",
   "metadata": {},
   "source": [
    "## Criando a SparkSession\n",
    "\n",
    "A SparkSession conecta o Python ao Spark.\n",
    "Nesta aula, vamos iniciar o Spark em modo local (uso didático).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Aula3\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0021369",
   "metadata": {},
   "source": [
    "## Criando dados com `spark.range(0, 10)`\n",
    "\n",
    "O comando `spark.range(0, 10)` cria um DataFrame automaticamente.\n",
    "\n",
    "- começa em 0\n",
    "- termina em 10 (**10 não entra**)\n",
    "\n",
    "Resultado esperado: valores de **0 a 9**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c715bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd41bf",
   "metadata": {},
   "source": [
    "## Visualizando os dados com show()\n",
    "\n",
    "Criar um DataFrame não exibe automaticamente os dados.\n",
    "Para visualizar o conteúdo, utilizamos o método `show()`.\n",
    "\n",
    "Esse comando exibe as linhas do DataFrame no ambiente de execução, permitindo observar os valores gerados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccac7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcda32",
   "metadata": {},
   "source": [
    "## Expandindo: `range` com variáveis\n",
    "\n",
    "Em vez de escrever os números direto no `range()`, podemos usar variáveis.\n",
    "Isso ajuda a entender que o intervalo pode mudar conforme a necessidade.\n",
    "\n",
    "Exemplo:\n",
    "- `inicio = 3`\n",
    "- `fim = 8`\n",
    "\n",
    "Isso deve gerar valores de **3 a 7** (porque o fim não entra).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a84321",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 3\n",
    "fim = 8\n",
    "\n",
    "df_var = spark.range(inicio, fim)\n",
    "df_var.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d38356",
   "metadata": {},
   "source": [
    "## Criando mais colunas no DataFrame\n",
    "\n",
    "O DataFrame criado com `spark.range()` tem apenas uma coluna (`id`).\n",
    "Podemos criar novas colunas a partir dela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2888ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_multi = (\n",
    "    df\n",
    "    .withColumn(\"id_dobro\", F.col(\"id\") * 2)\n",
    "    .withColumn(\"id_quadrado\", F.col(\"id\") * F.col(\"id\"))\n",
    ")\n",
    "\n",
    "df_multi.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8cf613",
   "metadata": {},
   "source": [
    "Neste exemplo:\n",
    "- `id_dobro` é o valor da coluna `id` multiplicado por 2\n",
    "- `id_quadrado` é o valor da coluna `id` ao quadrado\n",
    "\n",
    "Agora o DataFrame possui **três colunas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f02e2a",
   "metadata": {},
   "source": [
    "## Estrutura básica de um script PySpark\n",
    "\n",
    "O fluxo mínimo de um script PySpark envolve:\n",
    "\n",
    "1. Importar as bibliotecas necessárias\n",
    "2. Criar a SparkSession\n",
    "3. Criar dados (DataFrame)\n",
    "4. Visualizar ou manipular os dados\n",
    "\n",
    "Essa estrutura será reutilizada em outros exemplos ao longo do curso.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
