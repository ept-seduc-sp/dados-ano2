{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wovpkj5-gTQn"
   },
   "source": [
    "# AULA 4\n",
    "\n",
    "Modificar e aprimorar o Pipeline implementado na Aula 3, explorando novas técnicas de processamento e comparação de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OmMXD4AmgWns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: RandomForest\n",
      "Acurácia: 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80        99\n",
      "           1       0.64      0.71      0.67        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.74       154\n",
      "weighted avg       0.76      0.75      0.76       154\n",
      "\n",
      "\n",
      "Modelo: LogisticRegression\n",
      "Acurácia: 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82        99\n",
      "           1       0.67      0.64      0.65        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.74       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "\n",
      "Melhor modelo: LogisticRegression com acurácia de 0.7597402597402597\n",
      "\n",
      "Processo concluído! O melhor modelo foi salvo e pode ser utilizado para previsões futuras.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Passo 1: Carregar o dataset\n",
    "file_path = \"[DADOS]ANO2C1B4S26A3A4_diabet1.csv\"  # Nome do arquivo deve estar correto\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Passo 2: Ajustar os nomes das colunas para evitar erros\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Definir colunas numéricas para o Pipeline\n",
    "num_features = [\"glucose\", \"bloodpressure\", \"bmi\", \"insulin\", \"age\", \"diabetespedigreefunction\"]\n",
    "\n",
    "# Passo 3: Criar um Pipeline para o Pré-processamento\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),  # Preenchendo valores ausentes com a média\n",
    "    ('scaler', StandardScaler())  # Normalizando os dados\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features)\n",
    "])\n",
    "\n",
    "# Passo 4: Divisão dos dados entre treino e teste\n",
    "X = df.drop(columns=[\"outcome\"])\n",
    "y = df[\"outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Passo 5: Definir os modelos a serem comparados\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=2000)\n",
    "}\n",
    "\n",
    "# Passo 6: Comparar Modelos dentro do Pipeline\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    print(\"Acurácia:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\nMelhor modelo: {best_model_name} com acurácia de {best_accuracy}\")\n",
    "\n",
    "# Passo 7: Ajuste de Hiperparâmetros usando GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "if best_model_name == 'RandomForest':\n",
    "    grid_search = GridSearchCV(\n",
    "        Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        param_grid,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"\\nMelhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Passo 8: Salvar o melhor modelo\n",
    "joblib.dump(best_model, \"melhor_modelo_diabetes.pkl\")\n",
    "\n",
    "print(\"\\nProcesso concluído! O melhor modelo foi salvo e pode ser utilizado para previsões futuras.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
