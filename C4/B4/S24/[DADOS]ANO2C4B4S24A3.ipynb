{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"text-align: center;\">CIÊNCIA DE DADOS</h1>\n",
    "<h1 style=\"text-align: center;\">Roteiro de Atividade Prática</h1>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Nome: ______________________________________________________________________________________      \n",
    "\n",
    "Turma: ______________\n",
    "\n",
    "\n",
    "**Componente:** Inteligência Artificial\n",
    "<br>\n",
    "**Unidade Curricular:** IA Generativa\n",
    "<br>\n",
    "**Tema da Semana:** Implantação de LLMs\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3: Exercícios de fixação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa\n",
    "- Executem o código abaixo.\n",
    "\n",
    "- Se as bibliotecas não tiverem instaladas, instale-as.\n",
    "\n",
    "- Acompanhem as instruções.\n",
    "\n",
    "- Observem a execução e discutam com seus colegas e professor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFWB_gqNTbvb"
   },
   "source": [
    "### Atualizar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WMdN-IhTg_H"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-huggingface transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li4bbKJETitf"
   },
   "source": [
    "### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-6Xz9QUTqr4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-yqEegWTuro"
   },
   "source": [
    "### Criar embeddings com modelo leve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwkEv8IDTx-g"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hgj0Xo9J8xyZ"
   },
   "source": [
    "### Criar uma base de conhecimento com nome de documento.txt\n",
    "**Neste exemplo iremos utilizar o texto em inglês, para isso utilize o google tradutor para adicionar mais informações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGPu6AZF80iB"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(\"dados\"):\n",
    "    os.makedirs(\"dados\")\n",
    "\n",
    "with open(\"dados/documento_aula3.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"XYZ Platform Terms of Use and Security\\n\\n\"\n",
    "        \"1. **Use of the Platform:** The user agrees to use the services of the XYZ Platform only for \" \"lawful purposes and in accordance with the established terms. Any attempt at fraudulent use will result in \" \"immediate blocking of the account.\\n\\n\"\n",
    "        \"2. **Data Privacy:** All information collected is stored securely and is never \" \"shared with third parties without the user's consent. The data is protected by encryption \"\n",
    "        \"and follows the standards of the General Data Protection Law (LGPD).\\n\\n\"\n",
    "        \"3. **Information Security:** The XYZ Platform implements two-factor authentication (2FA) to \"\n",
    "        \"protect access to accounts. We recommend that users enable this functionality to increase \"\n",
    "        \"security.\\n\\n\"\n",
    "        \"4. **User Rights:** Users have the right to request the deletion of their data at any \"\n",
    "        \"time. To do so, simply contact us by email at suporte@xyz.com.\\n\\n\"\n",
    "        \"5. **Updates to the Terms:** The XYZ Platform may update its terms of use periodically. \"\n",
    "        \"Users will be notified of relevant changes via email or directly on the platform.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMdd7XsK8_q-"
   },
   "source": [
    "### Criar banco de vetores FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BumkCfw9G23"
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"dados/documento_aula3.txt\")\n",
    "documentos = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documentos_divididos = text_splitter.split_documents(documentos)\n",
    "vectorstore = FAISS.from_documents(documentos_divididos, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1olFxeDC9IMC"
   },
   "source": [
    "### Criar modelo LLM leve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4PzwFmU9NT1"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=\"gpt2\", max_new_tokens=100, temperature=0.7, pad_token_id=50256)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBDNNVoy9Qbu"
   },
   "source": [
    "### Criar a cadeia de recuperação e resposta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sevWiIDN9Sb1"
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6S20EXW9Ugk"
   },
   "source": [
    "### Teste do sistema com RAG com multiplas perguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL50vcEJTQ5y"
   },
   "outputs": [],
   "source": [
    "perguntas = [\n",
    "    \"What are the rights of users on the XYZ Platform?\",\n",
    "    \"Does the XYZ Platform share my data with third parties?\",\n",
    "    \"How can I protect my account?\",\n",
    "    \"What happens if I violate the terms of use?\"\n",
    "]\n",
    "\n",
    "for pergunta in perguntas:\n",
    "    print(\"\\n================================================\\n\")\n",
    "    resposta = qa.invoke({\"query\": pergunta})\n",
    "    print(f\"\\n Pergunta: {pergunta}\")\n",
    "    print(f\"\\nPergunta/Query:\\n\", resposta['query'])\n",
    "    print(f\"\\nResultado:\\n\", resposta['result'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
