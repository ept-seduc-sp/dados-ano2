{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8wj4Sf5c2aJ"
   },
   "source": [
    "\n",
    "<h1 style=\"text-align: center;\">CI√äNCIA DE DADOS</h1>\n",
    "<h1 style=\"text-align: center;\">Roteiro de Atividade Pr√°tica - PROFESSOR</h1>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsXxX6j-QiT6"
   },
   "source": [
    "# AULA 1 - REVIS√ÉO E EXERC√çCIOS PARTE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAMhvuKRDhyd"
   },
   "source": [
    "### Passo a Passo no c√≥digo gerado e ap√≥s o c√≥digo h√° uma explica√ß√£o clara e objetivo de tudo o que foi feito, al√©m do mesmo estar todo comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JoIl_gXBVnoW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura do dataset: ['version', 'data']\n",
      "Exemplo de amostra extra√≠da: {'qas': [{'question': 'What New York thoroughfare is Museum Mile located on?', 'id': '56d10c1f17492d1400aab806', 'answers': [{'text': 'Fifth Avenue', 'answer_start': 161}], 'is_impossible': False}, {'question': 'In what borough is Museum Mile located?', 'id': '56d10c1f17492d1400aab807', 'answers': [{'text': 'Manhattan', 'answer_start': 235}], 'is_impossible': False}, {'question': 'When was the Guggenheim built?', 'id': '56d10c1f17492d1400aab808', 'answers': [{'text': '1959', 'answer_start': 672}], 'is_impossible': False}, {'question': 'In what year was the grand opening of the Museum for African Art on 110th Street?', 'id': '56d10c1f17492d1400aab809', 'answers': [{'text': '2012', 'answer_start': 693}], 'is_impossible': False}, {'question': 'In what part of Manhattan is the Museum Mile located?', 'id': '56d10c1f17492d1400aab80a', 'answers': [{'text': 'Upper East Side', 'answer_start': 216}], 'is_impossible': False}], 'context': \"New York City is home to hundreds of cultural institutions and historic sites, many of which are internationally known. Museum Mile is the name for a section of Fifth Avenue running from 82nd to 105th streets on the Upper East Side of Manhattan, in an area sometimes called Upper Carnegie Hill. The Mile, which contains one of the densest displays of culture in the world, is actually three blocks longer than one mile (1.6 km). Ten museums occupy the length of this section of Fifth Avenue. The tenth museum, the Museum for African Art, joined the ensemble in 2009, however its Museum at 110th Street, the first new museum constructed on the Mile since the Guggenheim in 1959, opened in late 2012. In addition to other programming, the museums collaborate for the annual Museum Mile Festival, held each year in June, to promote the museums and increase visitation. Many of the world's most lucrative art auctions are held in New York City.\"}\n",
      "Amostra de 1% do SQuAD gerada e salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Carregar o dataset SQuAD (ajustar o caminho conforme necess√°rio)\n",
    "with open('[DADOS]ANO2C4B4S27A1A2_DATASET_train-v2.0.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Exibir a estrutura do dataset\n",
    "print(f\"Estrutura do dataset: {list(squad_data.keys())}\")\n",
    "\n",
    "# Acessar as perguntas e respostas\n",
    "perguntas_respostas = squad_data['data']\n",
    "\n",
    "# Gerar 1% dos dados\n",
    "amostra = []\n",
    "\n",
    "for artigo in perguntas_respostas:\n",
    "    # Selecione 1% aleat√≥rio de perguntas de cada artigo para a execu√ß√£o ficar mais r√°pida\n",
    "    amostra_artigo = random.sample(artigo['paragraphs'], int(0.01 * len(artigo['paragraphs'])))\n",
    "    amostra.extend(amostra_artigo)\n",
    "\n",
    "# Verificar a amostra extra√≠da\n",
    "print(f\"Exemplo de amostra extra√≠da: {amostra[0]}\")\n",
    "\n",
    "# Salvar os 1% extra√≠dos em um novo arquivo\n",
    "with open('amostra_squad_1percent.json', 'w') as f:\n",
    "    json.dump({'data': amostra}, f)\n",
    "\n",
    "print(\"Amostra de 1% do SQuAD gerada e salva com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o4bq5AZpBeE"
   },
   "source": [
    "### Importar e utilizar a amostra gerada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6yas2XbpWk4B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data'])\n",
      "[{'qas': [{'question': 'Which tunnel do 120,000 vehicles travel through a day in NYC?', 'id': '56d00bc5234ae51400d9c2cb', 'answers': [{'text': 'The Lincoln Tunnel', 'answer_start': 104}], 'is_impossible': False}, {'question': 'The Holland Tunnel opened in what year?', 'id': '56d00bc5234ae51400d9c2cc', 'answers': [{'text': '1927', 'answer_start': 614}], 'is_impossible': False}, {'question': 'The Queens-Midtown Tunnel was finished in what year?', 'id': '56d00bc5234ae51400d9c2cd', 'answers': [{'text': '1940', 'answer_start': 810}], 'is_impossible': False}, {'question': 'Who was the first person to drive through The Queens-Midtown Tunnel?', 'id': '56d00bc5234ae51400d9c2ce', 'answers': [{'text': 'President Franklin D. Roosevelt', 'answer_start': 816}], 'is_impossible': False}, {'question': 'How many vehicles utilize the Lincoln Tunnel daily?', 'id': '56d11bca17492d1400aab9a1', 'answers': [{'text': '120,000', 'answer_start': 138}], 'is_impossible': False}, {'question': 'What body of water is above the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a2', 'answers': [{'text': 'Hudson River', 'answer_start': 171}], 'is_impossible': False}, {'question': 'What borough is connected to New Jersey via the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a3', 'answers': [{'text': 'Manhattan', 'answer_start': 0}], 'is_impossible': False}, {'question': 'In what New Jersey city does the Holland Tunnel terminate?', 'id': '56d11bca17492d1400aab9a4', 'answers': [{'text': 'Jersey City', 'answer_start': 508}], 'is_impossible': False}, {'question': 'Who drove through the Queens-Midtown Tunnel before anyone else?', 'id': '56d11bca17492d1400aab9a5', 'answers': [{'text': 'Franklin D. Roosevelt', 'answer_start': 826}], 'is_impossible': False}], 'context': \"Manhattan Island is linked to New York City's outer boroughs and New Jersey by several tunnels as well. The Lincoln Tunnel, which carries 120,000 vehicles a day under the Hudson River between New Jersey and Midtown Manhattan, is the busiest vehicular tunnel in the world. The tunnel was built instead of a bridge to allow unfettered passage of large passenger and cargo ships that sailed through New York Harbor and up the Hudson River to Manhattan's piers. The Holland Tunnel, connecting Lower Manhattan to Jersey City, New Jersey, was the world's first mechanically ventilated vehicular tunnel when it opened in 1927. The Queens-Midtown Tunnel, built to relieve congestion on the bridges connecting Manhattan with Queens and Brooklyn, was the largest non-federal project in its time when it was completed in 1940. President Franklin D. Roosevelt was the first person to drive through it. The Hugh L. Carey Tunnel runs underneath Battery Park and connects the Financial District at the southern tip of Manhattan to Red Hook in Brooklyn.\"}, {'qas': [{'question': 'When did Gautama Buddha discover the Middle Way?', 'id': '56d0a9c3234ae51400d9c40e', 'answers': [{'text': 'prior to his enlightenment', 'answer_start': 144}], 'is_impossible': False}, {'question': 'An important guiding priciple of Buddhist practice is what?', 'id': '56d1d643e7d4791d00902289', 'answers': [{'text': 'the Middle Way', 'answer_start': 55}], 'is_impossible': False}, {'question': 'Guatama discovered the middle path before his what?', 'id': '56d1d643e7d4791d0090228a', 'answers': [{'text': 'enlightenment', 'answer_start': 157}], 'is_impossible': False}], 'context': 'An important guiding principle of Buddhist practice is the Middle Way (or Middle Path), which is said to have been discovered by Gautama Buddha prior to his enlightenment. The Middle Way has several definitions:'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carregar a amostra de 1% do dataset SQuAD\n",
    "with open('amostra_squad_1percent.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "print(squad_data.keys())\n",
    "# Verificar a estrutura da amostra carregada\n",
    "#print(f\"Exemplo de estrutura do dataset: {squad_data.keys()}\")  # Verificar as principais chaves\n",
    "print(squad_data['data'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm1X29OmDVVk",
    "outputId": "4fe52ae6-10d6-4230-c735-520c04e6eafe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves do dataset: dict_keys(['data'])\n",
      "Exemplo de dados: [{'qas': [{'question': 'Which tunnel do 120,000 vehicles travel through a day in NYC?', 'id': '56d00bc5234ae51400d9c2cb', 'answers': [{'text': 'The Lincoln Tunnel', 'answer_start': 104}], 'is_impossible': False}, {'question': 'The Holland Tunnel opened in what year?', 'id': '56d00bc5234ae51400d9c2cc', 'answers': [{'text': '1927', 'answer_start': 614}], 'is_impossible': False}, {'question': 'The Queens-Midtown Tunnel was finished in what year?', 'id': '56d00bc5234ae51400d9c2cd', 'answers': [{'text': '1940', 'answer_start': 810}], 'is_impossible': False}, {'question': 'Who was the first person to drive through The Queens-Midtown Tunnel?', 'id': '56d00bc5234ae51400d9c2ce', 'answers': [{'text': 'President Franklin D. Roosevelt', 'answer_start': 816}], 'is_impossible': False}, {'question': 'How many vehicles utilize the Lincoln Tunnel daily?', 'id': '56d11bca17492d1400aab9a1', 'answers': [{'text': '120,000', 'answer_start': 138}], 'is_impossible': False}, {'question': 'What body of water is above the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a2', 'answers': [{'text': 'Hudson River', 'answer_start': 171}], 'is_impossible': False}, {'question': 'What borough is connected to New Jersey via the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a3', 'answers': [{'text': 'Manhattan', 'answer_start': 0}], 'is_impossible': False}, {'question': 'In what New Jersey city does the Holland Tunnel terminate?', 'id': '56d11bca17492d1400aab9a4', 'answers': [{'text': 'Jersey City', 'answer_start': 508}], 'is_impossible': False}, {'question': 'Who drove through the Queens-Midtown Tunnel before anyone else?', 'id': '56d11bca17492d1400aab9a5', 'answers': [{'text': 'Franklin D. Roosevelt', 'answer_start': 826}], 'is_impossible': False}], 'context': \"Manhattan Island is linked to New York City's outer boroughs and New Jersey by several tunnels as well. The Lincoln Tunnel, which carries 120,000 vehicles a day under the Hudson River between New Jersey and Midtown Manhattan, is the busiest vehicular tunnel in the world. The tunnel was built instead of a bridge to allow unfettered passage of large passenger and cargo ships that sailed through New York Harbor and up the Hudson River to Manhattan's piers. The Holland Tunnel, connecting Lower Manhattan to Jersey City, New Jersey, was the world's first mechanically ventilated vehicular tunnel when it opened in 1927. The Queens-Midtown Tunnel, built to relieve congestion on the bridges connecting Manhattan with Queens and Brooklyn, was the largest non-federal project in its time when it was completed in 1940. President Franklin D. Roosevelt was the first person to drive through it. The Hugh L. Carey Tunnel runs underneath Battery Park and connects the Financial District at the southern tip of Manhattan to Red Hook in Brooklyn.\"}, {'qas': [{'question': 'When did Gautama Buddha discover the Middle Way?', 'id': '56d0a9c3234ae51400d9c40e', 'answers': [{'text': 'prior to his enlightenment', 'answer_start': 144}], 'is_impossible': False}, {'question': 'An important guiding priciple of Buddhist practice is what?', 'id': '56d1d643e7d4791d00902289', 'answers': [{'text': 'the Middle Way', 'answer_start': 55}], 'is_impossible': False}, {'question': 'Guatama discovered the middle path before his what?', 'id': '56d1d643e7d4791d0090228a', 'answers': [{'text': 'enlightenment', 'answer_start': 157}], 'is_impossible': False}], 'context': 'An important guiding principle of Buddhist practice is the Middle Way (or Middle Path), which is said to have been discovered by Gautama Buddha prior to his enlightenment. The Middle Way has several definitions:'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Which tunnel do 120,000 vehicles travel through a day in NYC?\n",
      "Resposta Esperada: The Lincoln Tunnel\n",
      "Resposta Gerada: Lincoln Tunnel\n",
      "\n",
      "Pergunta: The Holland Tunnel opened in what year?\n",
      "Resposta Esperada: 1927\n",
      "Resposta Gerada: The Holland Tunnel, connecting Lower Manha\n",
      "\n",
      "Pergunta: The Queens-Midtown Tunnel was finished in what year?\n",
      "Resposta Esperada: 1940\n",
      "Resposta Gerada: Manhattan\n",
      "\n",
      "Pergunta: Who was the first person to drive through The Queens-Midtown Tunnel?\n",
      "Resposta Esperada: President Franklin D. Roosevelt\n",
      "Resposta Gerada: passenger and cargo ships\n",
      "\n",
      "Pergunta: How many vehicles utilize the Lincoln Tunnel daily?\n",
      "Resposta Esperada: 120,000\n",
      "Resposta Gerada: 120,000\n",
      "\n",
      "Pergunta: What body of water is above the Lincoln Tunnel?\n",
      "Resposta Esperada: Hudson River\n",
      "Resposta Gerada: Hudson River\n",
      "\n",
      "Pergunta: What borough is connected to New Jersey via the Lincoln Tunnel?\n",
      "Resposta Esperada: Manhattan\n",
      "Resposta Gerada: Manhattan\n",
      "\n",
      "Pergunta: In what New Jersey city does the Holland Tunnel terminate?\n",
      "Resposta Esperada: Jersey City\n",
      "Resposta Gerada: Lower Manha\n",
      "\n",
      "Pergunta: Who drove through the Queens-Midtown Tunnel before anyone else?\n",
      "Resposta Esperada: Franklin D. Roosevelt\n",
      "Resposta Gerada: large passenger and cargo ships\n",
      "\n",
      "Pergunta: When did Gautama Buddha discover the Middle Way?\n",
      "Resposta Esperada: prior to his enlightenment\n",
      "Resposta Gerada: prior to his enlightenment\n",
      "\n",
      "Pergunta: An important guiding priciple of Buddhist practice is what?\n",
      "Resposta Esperada: the Middle Way\n",
      "Resposta Gerada: the Middle Way\n",
      "\n",
      "Pergunta: Guatama discovered the middle path before his what?\n",
      "Resposta Esperada: enlightenment\n",
      "Resposta Gerada: enlightenment\n",
      "\n",
      "Pergunta: What was the fist song released by Kelly Clarkson after winning American Idol?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: What film did Kelly Clarkson and Justin Guarini star in after they were on American Idol?\n",
      "Resposta Esperada: From Justin to Kelly\n",
      "Resposta Gerada: From Justin to Kelly\n",
      "\n",
      "Pergunta: How many albums has Kelly Clarkson sold around the world?\n",
      "Resposta Esperada: more than 23 million\n",
      "Resposta Gerada: 38\n",
      "\n",
      "Pergunta: What song did Kelly Clarkson perform during the finale?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: What did Clarkson sing during the finale?\n",
      "Resposta Esperada: the coronation song\n",
      "Resposta Gerada: coronation song\n",
      "\n",
      "Pergunta: What was the name of the song?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: Which record did the song break, which was the biggest leap to the top of the Billboard charts?\n",
      "Resposta Esperada: The Beatles\n",
      "Resposta Gerada: Beatles\n",
      "\n",
      "Pergunta: What was the name of the film that the two finalists made together?\n",
      "Resposta Esperada: From Justin to Kelly\n",
      "Resposta Gerada: From Justin to Kelly\n",
      "\n",
      "Pergunta: How many worldwide album sales has Kelly Clarkson had since winning Idol?\n",
      "Resposta Esperada: more than 23 million\n",
      "Resposta Gerada: 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o dataset de amostra SQuAD\n",
    "file_path = 'amostra_squad_1percent.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Verificar a estrutura da amostra carregada\n",
    "print(f\"Chaves do dataset: {squad_data.keys()}\")\n",
    "print(f\"Exemplo de dados: {squad_data['data'][:2]}\")\n",
    "\n",
    "# Carregar o pipeline de Perguntas e Respostas com o modelo BERT\n",
    "nlp = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "# Fun√ß√£o para buscar respostas baseadas na consulta\n",
    "def buscar_resposta(pergunta, contexto):\n",
    "    # Limitar o tamanho do contexto (ajustando o tamanho m√°ximo de\n",
    "    #500 caracteres para resposta mais eficiente)\n",
    "    max_contexto_length = 500  # Ajustando para 150 caracteres as respostas ficam incoerentes\n",
    "    if len(contexto) > max_contexto_length:\n",
    "        contexto = contexto[:max_contexto_length]  # Truncando o contexto\n",
    "\n",
    "    # Tentar recuperar a resposta\n",
    "    try:\n",
    "        return nlp(question=pergunta, context=contexto)['answer']\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na gera√ß√£o da resposta: {e}\")\n",
    "        return \"Resposta n√£o dispon√≠vel\"\n",
    "\n",
    "contador = 0\n",
    "# Testar o modelo com as perguntas extra√≠das da amostra\n",
    "for artigo in squad_data['data']:\n",
    "    contador += 1\n",
    "\n",
    "    if contador == 5: # executa apenas os 5 primeiros artigos para ficar mais r√°pido.\n",
    "            break\n",
    "    for qa in artigo['qas']:\n",
    "        \n",
    "        pergunta = qa['question']\n",
    "\n",
    "        # Verificar se a lista 'answers' est√° vazia antes de acessar\n",
    "        if qa['answers']:\n",
    "            resposta_correta = qa['answers'][0]['text']  # Resposta correta (para compara√ß√£o)\n",
    "        else:\n",
    "            resposta_correta = \"N√£o dispon√≠vel\"\n",
    "\n",
    "        # A chave correta do contexto √© 'context', e ele deve ser acessado diretamente aqui\n",
    "        contexto = artigo.get('context', 'Informa√ß√£o n√£o dispon√≠vel')  # Ajuste para a chave correta de contexto\n",
    "\n",
    "        # Recupera√ß√£o da resposta\n",
    "        resposta = buscar_resposta(pergunta, contexto)\n",
    "\n",
    "        print(f'Pergunta: {pergunta}\\nResposta Esperada: {resposta_correta}\\nResposta Gerada: {resposta}\\n')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0BRExt_Uaau"
   },
   "source": [
    "# Explica√ß√£o do C√≥digo :\n",
    "Carregamento da Amostra de 1% do Dataset SQuAD:\n",
    "O arquivo amostra_squad_5percent.json √© carregado utilizando json.load(). Essa amostra cont√©m 1% dos dados do SQuAD.\n",
    "\n",
    "**Acessando Perguntas e Respostas:**\n",
    "\n",
    "O dataset cont√©m perguntas e respostas dentro de artigos e par√°grafos, ent√£o estamos acessando essas informa√ß√µes atrav√©s de squad_data['data'].\n",
    "\n",
    "**Modelo BERT para Perguntas e Respostas:**\n",
    "\n",
    "Usamos o modelo DistilBERT pr√©-treinado da HuggingFace, adequado para tarefas de perguntas e respostas. A fun√ß√£o pipeline(\"question-answering\") permite carregar o modelo facilmente.\n",
    "\n",
    "**Busca de Respostas:**\n",
    "\n",
    "A fun√ß√£o buscar_resposta() recebe a pergunta e o contexto (o par√°grafo onde a resposta ser√° procurada) e retorna a resposta gerada pelo modelo.\n",
    "\n",
    "**Testando com Perguntas da Amostra:**\n",
    "\n",
    "O c√≥digo percorre todos os artigos e par√°grafos da amostra, fazendo uma pergunta de cada vez e gerando a resposta. A resposta gerada √© ent√£o impressa no console para que o aluno possa visualizar a qualidade da recupera√ß√£o de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX7bIUWOFCqf"
   },
   "source": [
    "**Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "- Escolhemos o dataset SQuAD e extra√≠mos uma amostra de 1% para trabalhar com perguntas e respostas reais.\n",
    "\n",
    "- Implementamos um sistema de recupera√ß√£o de conhecimento assistida, utilizando um modelo de Perguntas e Respostas (QA) baseado em BERT.\n",
    "\n",
    "- Processamos perguntas e respostas, garantindo que o contexto correto fosse passado ao modelo para melhorar a precis√£o das respostas.\n",
    "\n",
    "- Avaliamos as respostas geradas, comparando-as com as respostas esperadas, identificando pontos de acerto e poss√≠veis melhorias na extra√ß√£o de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxWZe8ljQznA"
   },
   "source": [
    "# AULA 2 - REVIS√ÉO E EXERC√çCIOS PARTE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5Wu96_7wCMv"
   },
   "source": [
    "### Passo a Passo: Solu√ß√£o da Atividade Pr√°tica - Exercicio e Revis√£o parte 2\n",
    "\n",
    "### Implementa√ß√£o de Recupera√ß√£o de Conhecimento com Fine-Tuning\n",
    "\n",
    "Este notebook tem como objetivo expandir a implementa√ß√£o de recupera√ß√£o de conhecimento assistida,\n",
    "aplicando frameworks como Hugging Face para desenvolver e testar uma aplica√ß√£o funcional.\n",
    "\n",
    "### Objetivos:\n",
    "- Explorar a diferen√ßa entre modelos pr√©-treinados e modelos ajustados (fine-tuned);\n",
    "- Aplicar um modelo de IA para responder perguntas baseadas em um dataset;\n",
    "- Comparar a precis√£o das respostas geradas por diferentes abordagens.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Importando as Bibliotecas Necess√°rias\n",
    "Primeiro, vamos importar as bibliotecas necess√°rias para o trabalho com o modelo de perguntas e respostas e para manipula√ß√£o do dataset:\n",
    "\n",
    " as bibliotecas necess√°rias para HuggingFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.28.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (2.6.0+cpu)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (1.5.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (2.6.0+cpu)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (0.28.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826,
     "referenced_widgets": [
      "19796f2cad8a4e17aff7137d903d2d58",
      "9f346295ffee4bc1a3bc305bd65e914e",
      "93229edeec244b0e9b80cf8569379e79",
      "cc7dac90d84f4ecbb67ae9bda2806866",
      "2505bf43c2264b5585db984bc5fd263c",
      "33da6664e9e342f6b2e61436dc7f49a4",
      "5c8fadab8b8d4bef800f2f496bbf5b25",
      "2cb6381951054840ae52ae1d0a40d1e0",
      "056b20b523c949e59b01d101570837ea",
      "a92c6a4df25843adb445f9bd9ad21199",
      "97d48847d9f4484b95c6400e84845888",
      "2ecd6f7de1044a5796056c853ad83cf9",
      "5655d76a1efa4636bec19dfd73fc7caa",
      "32ecd895164d4146ac4bc71923717807",
      "4f1b2ee0c7d74d41b8b547042b29b7a2",
      "ce0c2f642bc641c9baff1c7f4c9278c9",
      "2292442810ca42e0a6fccc4610845c66",
      "09fdc85e80d84eaf8165dbe6d7a84f67",
      "61406756d27d42558d052494019f7fbb",
      "2769e23ed19545a586f6e8d11cb13a78",
      "f4723e46cd0e4ae6a761ff9d3f7cf557",
      "227caf2413f149daa5c43dbaa018892a"
     ]
    },
    "id": "9sUU8LzcpDDO",
    "outputId": "caa8d229-c3df-4066-a030-b0afa450a199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 1309.39 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 569.26 examples/s]\n",
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Daniel Viana\\AppData\\Local\\Temp\\ipykernel_9324\\848344707.py:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.993261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.654542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.301044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pergunta: Which tunnel do 120,000 vehicles travel through a day in NYC?\n",
      "Resposta Verdadeira: The Lincoln Tunnel\n",
      "Resposta do Modelo Ajustado: [CLS]\n",
      "\n",
      "Pergunta: The Holland Tunnel opened in what year?\n",
      "Resposta Verdadeira: 1927\n",
      "Resposta do Modelo Ajustado: 1927\n",
      "\n",
      "Pergunta: The Queens-Midtown Tunnel was finished in what year?\n",
      "Resposta Verdadeira: 1940\n",
      "Resposta do Modelo Ajustado: 1940\n",
      "\n",
      "Pergunta: Who was the first person to drive through The Queens-Midtown Tunnel?\n",
      "Resposta Verdadeira: President Franklin D. Roosevelt\n",
      "Resposta do Modelo Ajustado: President Franklin D. Roosevelt\n",
      "\n",
      "Pergunta: How many vehicles utilize the Lincoln Tunnel daily?\n",
      "Resposta Verdadeira: 120,000\n",
      "Resposta do Modelo Ajustado: 120, 000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Desativar o Weights & Biases (W&B)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\"\"\"\n",
    "## 1. Carregar o Dataset da Aula 1\n",
    "\n",
    "O dataset utilizado cont√©m perguntas e respostas extra√≠das do conjunto de dados SQuAD.\n",
    "O objetivo √© utilizar este dataset para testar a performance dos modelos na tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = \"amostra_squad_1percent.json\"\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\"\"\"\n",
    "## 2. Extra√ß√£o das Perguntas e Contextos\n",
    "\n",
    "O dataset cont√©m perguntas associadas a um contexto. Extrairemos esses pares para alimentar o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def extract_qa_pairs(data):\n",
    "    qa_pairs = []\n",
    "    for item in data[\"data\"]:\n",
    "        context = item[\"context\"]\n",
    "        for qa in item[\"qas\"]:\n",
    "            question = qa[\"question\"]\n",
    "            answer = qa[\"answers\"][0][\"text\"] if qa[\"answers\"] else \"\"\n",
    "            qa_pairs.append((context, question, answer))\n",
    "    return qa_pairs\n",
    "\n",
    "qa_pairs = extract_qa_pairs(data)\n",
    "\n",
    "\"\"\"\n",
    "## 3. Modelo Pr√©-Treinado\n",
    "\n",
    "Usamos um modelo pr√©-treinado do Hugging Face (`deepset/bert-base-cased-squad2`)\n",
    "para realizar a tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
    "\n",
    "def hf_answer(question, context):\n",
    "    return qa_pipeline({\"question\": question, \"context\": context})[\"answer\"]\n",
    "\n",
    "\"\"\"\n",
    "## 4. Teste do Modelo Pr√©-Treinado\n",
    "\n",
    "Selecionamos algumas perguntas do dataset e geramos respostas utilizando o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def test_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        hf_resp = hf_answer(question, context)\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo\": hf_resp\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_results = test_model()\n",
    "\n",
    "\"\"\"\n",
    "## 5. Fine-Tuning do Modelo\n",
    "\n",
    "Aqui treinaremos o modelo `deepset/bert-base-cased-squad2` no dataset espec√≠fico para melhorar a precis√£o.\n",
    "\"\"\"\n",
    "\n",
    "# Carregar o modelo e tokenizer\n",
    "model_name = \"deepset/bert-base-cased-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = tokenizer(examples[\"question\"], examples[\"context\"], truncation=True, padding=\"max_length\", max_length=384)\n",
    "    inputs[\"start_positions\"] = [context.find(ans[\"text\"][0]) for context, ans in zip(examples[\"context\"], examples[\"answers\"])]\n",
    "    inputs[\"end_positions\"] = [start + len(ans[\"text\"][0]) for start, ans in zip(inputs[\"start_positions\"], examples[\"answers\"])]\n",
    "    return inputs\n",
    "\n",
    "# Criar um dataset estruturado para fine-tuning\n",
    "dataset_dict = {\"question\": [], \"context\": [], \"answers\": []}\n",
    "for context, question, answer in qa_pairs:\n",
    "    dataset_dict[\"question\"].append(question)\n",
    "    dataset_dict[\"context\"].append(context)\n",
    "    dataset_dict[\"answers\"].append({\"text\": [answer], \"answer_start\": [context.find(answer)]})\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "dataset = dataset.train_test_split(test_size=0.2)  # Separar treino e valida√ß√£o\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Configura√ß√£o do treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"  # Desativar Weights & Biases\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "\"\"\"\n",
    "## 6. Teste do Modelo Ajustado\n",
    "\n",
    "Ap√≥s o fine-tuning, testamos o modelo novamente para comparar a performance com o modelo pr√©-treinado.\n",
    "\"\"\"\n",
    "\n",
    "def test_finetuned_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=384)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo Ajustado\": answer\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_finetuned_results = test_finetuned_model()\n",
    "\n",
    "\"\"\"\n",
    "## 7. Compara√ß√£o de Resultados\n",
    "\n",
    "Mostramos as respostas geradas pelo modelo pr√©-treinado e pelo modelo ajustado para analisar diferen√ßas na precis√£o.\n",
    "\"\"\"\n",
    "\n",
    "for result in test_finetuned_results:\n",
    "    print(\"\\nPergunta:\", result[\"Pergunta\"])\n",
    "    print(\"Resposta Verdadeira:\", result[\"Resposta Verdadeira\"])\n",
    "    print(\"Resposta do Modelo Ajustado:\", result[\"Resposta do Modelo Ajustado\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opRJLw_Tr61s"
   },
   "source": [
    "\n",
    "### **Conclus√£o da Atividade**\n",
    "\n",
    "### **1. Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "Esta atividade teve como objetivo expandir a implementa√ß√£o de recupera√ß√£o de conhecimento assistida, utilizando modelos de IA para perguntas e respostas.\n",
    "\n",
    "Foram testadas abordagens com modelos pr√©-treinados e ajustados (fine-tuned), utilizando o framework Hugging Face e um subconjunto do dataset SQuAD.\n",
    "\n",
    "### **2. Metodologia**\n",
    "\n",
    "A implementa√ß√£o seguiu os seguintes passos:\n",
    "\n",
    "Carregamento do Dataset utilizado tamb√©m na aula1: O conjunto de dados foi extra√≠do e processado.\n",
    "\n",
    "Aplica√ß√£o do Modelo Pr√©-Treinado: Foi utilizado o modelo deepset/bert-base-cased-squad2 para responder perguntas diretamente.\n",
    "\n",
    "Fine-Tuning do Modelo: Ajustamos o modelo com um subconjunto dos dados para melhorar sua precis√£o.\n",
    "\n",
    "Compara√ß√£o de Resultados: Avaliamos o desempenho do modelo pr√©-treinado versus o modelo ajustado.\n",
    "\n",
    "Desativa√ß√£o de Depend√™ncias Externas: Garantimos que o c√≥digo n√£o requer chaves de API nem conex√£o com o W&B.\n",
    "\n",
    "### **3. Resultados Obtidos**\n",
    "\n",
    "O modelo pr√©-treinado conseguiu gerar respostas relevantes, mas apresentou limita√ß√µes em perguntas mais complexas.\n",
    "\n",
    "O modelo ajustado demonstrou melhorias significativas na precis√£o das respostas, especialmente em perguntas espec√≠ficas do dataset.\n",
    "\n",
    "O tempo de treinamento foi otimizado ajustando o batch size e o n√∫mero de √©pocas.\n",
    "\n",
    "Desativamos o W&B para garantir um ambiente de execu√ß√£o independente.\n",
    "\n",
    "### **4. Dificuldades Encontradas e Solu√ß√µes**\n",
    "\n",
    "4.1 Pesos n√£o utilizados\n",
    "\n",
    "Problema: Avisos sobre pesos n√£o utilizados ao carregar o modelo.\n",
    "Solu√ß√£o: Garantimos que o modelo correto (deepset/bert-base-cased-squad2) foi utilizado para evitar incompatibilidades.\n",
    "\n",
    "4.2 Falta de Conjunto de Valida√ß√£o\n",
    "\n",
    "Problema: O Trainer exigia um dataset de valida√ß√£o.\n",
    "Solu√ß√£o: Criamos um conjunto de valida√ß√£o separado do dataset de treinamento.\n",
    "\n",
    "4.3 Requisi√ß√£o de Chave de API\n",
    "\n",
    "Problema: O W&B exigia autentica√ß√£o.\n",
    "Solu√ß√£o: Desativamos o W&B com os.environ[\"WANDB_DISABLED\"] = \"true\" e report_to=\"none\".\n",
    "\n",
    "### **5. Conclus√£o**\n",
    "\n",
    "A atividade demonstrou a import√¢ncia do **fine-tuning** para melhorar o desempenho de modelos de perguntas e respostas. O modelo ajustado apresentou respostas mais precisas e contextualizadas, destacando a relev√¢ncia da adapta√ß√£o do modelo ao dom√≠nio espec√≠fico. A implementa√ß√£o final permitiu um fluxo de trabalho eficiente e livre de depend√™ncias externas, garantindo replicabilidade.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "056b20b523c949e59b01d101570837ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "09fdc85e80d84eaf8165dbe6d7a84f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19796f2cad8a4e17aff7137d903d2d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f346295ffee4bc1a3bc305bd65e914e",
       "IPY_MODEL_93229edeec244b0e9b80cf8569379e79",
       "IPY_MODEL_cc7dac90d84f4ecbb67ae9bda2806866"
      ],
      "layout": "IPY_MODEL_2505bf43c2264b5585db984bc5fd263c"
     }
    },
    "227caf2413f149daa5c43dbaa018892a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2292442810ca42e0a6fccc4610845c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2505bf43c2264b5585db984bc5fd263c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2769e23ed19545a586f6e8d11cb13a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cb6381951054840ae52ae1d0a40d1e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ecd6f7de1044a5796056c853ad83cf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5655d76a1efa4636bec19dfd73fc7caa",
       "IPY_MODEL_32ecd895164d4146ac4bc71923717807",
       "IPY_MODEL_4f1b2ee0c7d74d41b8b547042b29b7a2"
      ],
      "layout": "IPY_MODEL_ce0c2f642bc641c9baff1c7f4c9278c9"
     }
    },
    "32ecd895164d4146ac4bc71923717807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61406756d27d42558d052494019f7fbb",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2769e23ed19545a586f6e8d11cb13a78",
      "value": 3
     }
    },
    "33da6664e9e342f6b2e61436dc7f49a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1b2ee0c7d74d41b8b547042b29b7a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4723e46cd0e4ae6a761ff9d3f7cf557",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_227caf2413f149daa5c43dbaa018892a",
      "value": "‚Äá3/3‚Äá[00:00&lt;00:00,‚Äá72.53‚Äáexamples/s]"
     }
    },
    "5655d76a1efa4636bec19dfd73fc7caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2292442810ca42e0a6fccc4610845c66",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_09fdc85e80d84eaf8165dbe6d7a84f67",
      "value": "Map:‚Äá100%"
     }
    },
    "5c8fadab8b8d4bef800f2f496bbf5b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61406756d27d42558d052494019f7fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93229edeec244b0e9b80cf8569379e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cb6381951054840ae52ae1d0a40d1e0",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_056b20b523c949e59b01d101570837ea",
      "value": 9
     }
    },
    "97d48847d9f4484b95c6400e84845888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f346295ffee4bc1a3bc305bd65e914e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33da6664e9e342f6b2e61436dc7f49a4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5c8fadab8b8d4bef800f2f496bbf5b25",
      "value": "Map:‚Äá100%"
     }
    },
    "a92c6a4df25843adb445f9bd9ad21199": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7dac90d84f4ecbb67ae9bda2806866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a92c6a4df25843adb445f9bd9ad21199",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_97d48847d9f4484b95c6400e84845888",
      "value": "‚Äá9/9‚Äá[00:00&lt;00:00,‚Äá199.70‚Äáexamples/s]"
     }
    },
    "ce0c2f642bc641c9baff1c7f4c9278c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4723e46cd0e4ae6a761ff9d3f7cf557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
