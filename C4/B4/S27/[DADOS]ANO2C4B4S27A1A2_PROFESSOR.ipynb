{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8wj4Sf5c2aJ"
   },
   "source": [
    "\n",
    "<h1 style=\"text-align: center;\">CIÊNCIA DE DADOS</h1>\n",
    "<h1 style=\"text-align: center;\">Roteiro de Atividade Prática - PROFESSOR</h1>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsXxX6j-QiT6"
   },
   "source": [
    "# AULA 1 - REVISÃO E EXERCÍCIOS PARTE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAMhvuKRDhyd"
   },
   "source": [
    "### Passo a Passo no código gerado e após o código há uma explicação clara e objetivo de tudo o que foi feito, além do mesmo estar todo comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JoIl_gXBVnoW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura do dataset: ['version', 'data']\n",
      "Exemplo de amostra extraída: {'qas': [{'question': 'What New York thoroughfare is Museum Mile located on?', 'id': '56d10c1f17492d1400aab806', 'answers': [{'text': 'Fifth Avenue', 'answer_start': 161}], 'is_impossible': False}, {'question': 'In what borough is Museum Mile located?', 'id': '56d10c1f17492d1400aab807', 'answers': [{'text': 'Manhattan', 'answer_start': 235}], 'is_impossible': False}, {'question': 'When was the Guggenheim built?', 'id': '56d10c1f17492d1400aab808', 'answers': [{'text': '1959', 'answer_start': 672}], 'is_impossible': False}, {'question': 'In what year was the grand opening of the Museum for African Art on 110th Street?', 'id': '56d10c1f17492d1400aab809', 'answers': [{'text': '2012', 'answer_start': 693}], 'is_impossible': False}, {'question': 'In what part of Manhattan is the Museum Mile located?', 'id': '56d10c1f17492d1400aab80a', 'answers': [{'text': 'Upper East Side', 'answer_start': 216}], 'is_impossible': False}], 'context': \"New York City is home to hundreds of cultural institutions and historic sites, many of which are internationally known. Museum Mile is the name for a section of Fifth Avenue running from 82nd to 105th streets on the Upper East Side of Manhattan, in an area sometimes called Upper Carnegie Hill. The Mile, which contains one of the densest displays of culture in the world, is actually three blocks longer than one mile (1.6 km). Ten museums occupy the length of this section of Fifth Avenue. The tenth museum, the Museum for African Art, joined the ensemble in 2009, however its Museum at 110th Street, the first new museum constructed on the Mile since the Guggenheim in 1959, opened in late 2012. In addition to other programming, the museums collaborate for the annual Museum Mile Festival, held each year in June, to promote the museums and increase visitation. Many of the world's most lucrative art auctions are held in New York City.\"}\n",
      "Amostra de 1% do SQuAD gerada e salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Carregar o dataset SQuAD (ajustar o caminho conforme necessário)\n",
    "with open('[DADOS]ANO2C4B4S27A1A2_DATASET_train-v2.0.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Exibir a estrutura do dataset\n",
    "print(f\"Estrutura do dataset: {list(squad_data.keys())}\")\n",
    "\n",
    "# Acessar as perguntas e respostas\n",
    "perguntas_respostas = squad_data['data']\n",
    "\n",
    "# Gerar 1% dos dados\n",
    "amostra = []\n",
    "\n",
    "for artigo in perguntas_respostas:\n",
    "    # Selecione 1% aleatório de perguntas de cada artigo para a execução ficar mais rápida\n",
    "    amostra_artigo = random.sample(artigo['paragraphs'], int(0.01 * len(artigo['paragraphs'])))\n",
    "    amostra.extend(amostra_artigo)\n",
    "\n",
    "# Verificar a amostra extraída\n",
    "print(f\"Exemplo de amostra extraída: {amostra[0]}\")\n",
    "\n",
    "# Salvar os 1% extraídos em um novo arquivo\n",
    "with open('amostra_squad_1percent.json', 'w') as f:\n",
    "    json.dump({'data': amostra}, f)\n",
    "\n",
    "print(\"Amostra de 1% do SQuAD gerada e salva com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o4bq5AZpBeE"
   },
   "source": [
    "### Importar e utilizar a amostra gerada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6yas2XbpWk4B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data'])\n",
      "[{'qas': [{'question': 'Which tunnel do 120,000 vehicles travel through a day in NYC?', 'id': '56d00bc5234ae51400d9c2cb', 'answers': [{'text': 'The Lincoln Tunnel', 'answer_start': 104}], 'is_impossible': False}, {'question': 'The Holland Tunnel opened in what year?', 'id': '56d00bc5234ae51400d9c2cc', 'answers': [{'text': '1927', 'answer_start': 614}], 'is_impossible': False}, {'question': 'The Queens-Midtown Tunnel was finished in what year?', 'id': '56d00bc5234ae51400d9c2cd', 'answers': [{'text': '1940', 'answer_start': 810}], 'is_impossible': False}, {'question': 'Who was the first person to drive through The Queens-Midtown Tunnel?', 'id': '56d00bc5234ae51400d9c2ce', 'answers': [{'text': 'President Franklin D. Roosevelt', 'answer_start': 816}], 'is_impossible': False}, {'question': 'How many vehicles utilize the Lincoln Tunnel daily?', 'id': '56d11bca17492d1400aab9a1', 'answers': [{'text': '120,000', 'answer_start': 138}], 'is_impossible': False}, {'question': 'What body of water is above the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a2', 'answers': [{'text': 'Hudson River', 'answer_start': 171}], 'is_impossible': False}, {'question': 'What borough is connected to New Jersey via the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a3', 'answers': [{'text': 'Manhattan', 'answer_start': 0}], 'is_impossible': False}, {'question': 'In what New Jersey city does the Holland Tunnel terminate?', 'id': '56d11bca17492d1400aab9a4', 'answers': [{'text': 'Jersey City', 'answer_start': 508}], 'is_impossible': False}, {'question': 'Who drove through the Queens-Midtown Tunnel before anyone else?', 'id': '56d11bca17492d1400aab9a5', 'answers': [{'text': 'Franklin D. Roosevelt', 'answer_start': 826}], 'is_impossible': False}], 'context': \"Manhattan Island is linked to New York City's outer boroughs and New Jersey by several tunnels as well. The Lincoln Tunnel, which carries 120,000 vehicles a day under the Hudson River between New Jersey and Midtown Manhattan, is the busiest vehicular tunnel in the world. The tunnel was built instead of a bridge to allow unfettered passage of large passenger and cargo ships that sailed through New York Harbor and up the Hudson River to Manhattan's piers. The Holland Tunnel, connecting Lower Manhattan to Jersey City, New Jersey, was the world's first mechanically ventilated vehicular tunnel when it opened in 1927. The Queens-Midtown Tunnel, built to relieve congestion on the bridges connecting Manhattan with Queens and Brooklyn, was the largest non-federal project in its time when it was completed in 1940. President Franklin D. Roosevelt was the first person to drive through it. The Hugh L. Carey Tunnel runs underneath Battery Park and connects the Financial District at the southern tip of Manhattan to Red Hook in Brooklyn.\"}, {'qas': [{'question': 'When did Gautama Buddha discover the Middle Way?', 'id': '56d0a9c3234ae51400d9c40e', 'answers': [{'text': 'prior to his enlightenment', 'answer_start': 144}], 'is_impossible': False}, {'question': 'An important guiding priciple of Buddhist practice is what?', 'id': '56d1d643e7d4791d00902289', 'answers': [{'text': 'the Middle Way', 'answer_start': 55}], 'is_impossible': False}, {'question': 'Guatama discovered the middle path before his what?', 'id': '56d1d643e7d4791d0090228a', 'answers': [{'text': 'enlightenment', 'answer_start': 157}], 'is_impossible': False}], 'context': 'An important guiding principle of Buddhist practice is the Middle Way (or Middle Path), which is said to have been discovered by Gautama Buddha prior to his enlightenment. The Middle Way has several definitions:'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carregar a amostra de 1% do dataset SQuAD\n",
    "with open('amostra_squad_1percent.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "print(squad_data.keys())\n",
    "# Verificar a estrutura da amostra carregada\n",
    "#print(f\"Exemplo de estrutura do dataset: {squad_data.keys()}\")  # Verificar as principais chaves\n",
    "print(squad_data['data'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm1X29OmDVVk",
    "outputId": "4fe52ae6-10d6-4230-c735-520c04e6eafe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves do dataset: dict_keys(['data'])\n",
      "Exemplo de dados: [{'qas': [{'question': 'Which tunnel do 120,000 vehicles travel through a day in NYC?', 'id': '56d00bc5234ae51400d9c2cb', 'answers': [{'text': 'The Lincoln Tunnel', 'answer_start': 104}], 'is_impossible': False}, {'question': 'The Holland Tunnel opened in what year?', 'id': '56d00bc5234ae51400d9c2cc', 'answers': [{'text': '1927', 'answer_start': 614}], 'is_impossible': False}, {'question': 'The Queens-Midtown Tunnel was finished in what year?', 'id': '56d00bc5234ae51400d9c2cd', 'answers': [{'text': '1940', 'answer_start': 810}], 'is_impossible': False}, {'question': 'Who was the first person to drive through The Queens-Midtown Tunnel?', 'id': '56d00bc5234ae51400d9c2ce', 'answers': [{'text': 'President Franklin D. Roosevelt', 'answer_start': 816}], 'is_impossible': False}, {'question': 'How many vehicles utilize the Lincoln Tunnel daily?', 'id': '56d11bca17492d1400aab9a1', 'answers': [{'text': '120,000', 'answer_start': 138}], 'is_impossible': False}, {'question': 'What body of water is above the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a2', 'answers': [{'text': 'Hudson River', 'answer_start': 171}], 'is_impossible': False}, {'question': 'What borough is connected to New Jersey via the Lincoln Tunnel?', 'id': '56d11bca17492d1400aab9a3', 'answers': [{'text': 'Manhattan', 'answer_start': 0}], 'is_impossible': False}, {'question': 'In what New Jersey city does the Holland Tunnel terminate?', 'id': '56d11bca17492d1400aab9a4', 'answers': [{'text': 'Jersey City', 'answer_start': 508}], 'is_impossible': False}, {'question': 'Who drove through the Queens-Midtown Tunnel before anyone else?', 'id': '56d11bca17492d1400aab9a5', 'answers': [{'text': 'Franklin D. Roosevelt', 'answer_start': 826}], 'is_impossible': False}], 'context': \"Manhattan Island is linked to New York City's outer boroughs and New Jersey by several tunnels as well. The Lincoln Tunnel, which carries 120,000 vehicles a day under the Hudson River between New Jersey and Midtown Manhattan, is the busiest vehicular tunnel in the world. The tunnel was built instead of a bridge to allow unfettered passage of large passenger and cargo ships that sailed through New York Harbor and up the Hudson River to Manhattan's piers. The Holland Tunnel, connecting Lower Manhattan to Jersey City, New Jersey, was the world's first mechanically ventilated vehicular tunnel when it opened in 1927. The Queens-Midtown Tunnel, built to relieve congestion on the bridges connecting Manhattan with Queens and Brooklyn, was the largest non-federal project in its time when it was completed in 1940. President Franklin D. Roosevelt was the first person to drive through it. The Hugh L. Carey Tunnel runs underneath Battery Park and connects the Financial District at the southern tip of Manhattan to Red Hook in Brooklyn.\"}, {'qas': [{'question': 'When did Gautama Buddha discover the Middle Way?', 'id': '56d0a9c3234ae51400d9c40e', 'answers': [{'text': 'prior to his enlightenment', 'answer_start': 144}], 'is_impossible': False}, {'question': 'An important guiding priciple of Buddhist practice is what?', 'id': '56d1d643e7d4791d00902289', 'answers': [{'text': 'the Middle Way', 'answer_start': 55}], 'is_impossible': False}, {'question': 'Guatama discovered the middle path before his what?', 'id': '56d1d643e7d4791d0090228a', 'answers': [{'text': 'enlightenment', 'answer_start': 157}], 'is_impossible': False}], 'context': 'An important guiding principle of Buddhist practice is the Middle Way (or Middle Path), which is said to have been discovered by Gautama Buddha prior to his enlightenment. The Middle Way has several definitions:'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Which tunnel do 120,000 vehicles travel through a day in NYC?\n",
      "Resposta Esperada: The Lincoln Tunnel\n",
      "Resposta Gerada: Lincoln Tunnel\n",
      "\n",
      "Pergunta: The Holland Tunnel opened in what year?\n",
      "Resposta Esperada: 1927\n",
      "Resposta Gerada: The Holland Tunnel, connecting Lower Manha\n",
      "\n",
      "Pergunta: The Queens-Midtown Tunnel was finished in what year?\n",
      "Resposta Esperada: 1940\n",
      "Resposta Gerada: Manhattan\n",
      "\n",
      "Pergunta: Who was the first person to drive through The Queens-Midtown Tunnel?\n",
      "Resposta Esperada: President Franklin D. Roosevelt\n",
      "Resposta Gerada: passenger and cargo ships\n",
      "\n",
      "Pergunta: How many vehicles utilize the Lincoln Tunnel daily?\n",
      "Resposta Esperada: 120,000\n",
      "Resposta Gerada: 120,000\n",
      "\n",
      "Pergunta: What body of water is above the Lincoln Tunnel?\n",
      "Resposta Esperada: Hudson River\n",
      "Resposta Gerada: Hudson River\n",
      "\n",
      "Pergunta: What borough is connected to New Jersey via the Lincoln Tunnel?\n",
      "Resposta Esperada: Manhattan\n",
      "Resposta Gerada: Manhattan\n",
      "\n",
      "Pergunta: In what New Jersey city does the Holland Tunnel terminate?\n",
      "Resposta Esperada: Jersey City\n",
      "Resposta Gerada: Lower Manha\n",
      "\n",
      "Pergunta: Who drove through the Queens-Midtown Tunnel before anyone else?\n",
      "Resposta Esperada: Franklin D. Roosevelt\n",
      "Resposta Gerada: large passenger and cargo ships\n",
      "\n",
      "Pergunta: When did Gautama Buddha discover the Middle Way?\n",
      "Resposta Esperada: prior to his enlightenment\n",
      "Resposta Gerada: prior to his enlightenment\n",
      "\n",
      "Pergunta: An important guiding priciple of Buddhist practice is what?\n",
      "Resposta Esperada: the Middle Way\n",
      "Resposta Gerada: the Middle Way\n",
      "\n",
      "Pergunta: Guatama discovered the middle path before his what?\n",
      "Resposta Esperada: enlightenment\n",
      "Resposta Gerada: enlightenment\n",
      "\n",
      "Pergunta: What was the fist song released by Kelly Clarkson after winning American Idol?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: What film did Kelly Clarkson and Justin Guarini star in after they were on American Idol?\n",
      "Resposta Esperada: From Justin to Kelly\n",
      "Resposta Gerada: From Justin to Kelly\n",
      "\n",
      "Pergunta: How many albums has Kelly Clarkson sold around the world?\n",
      "Resposta Esperada: more than 23 million\n",
      "Resposta Gerada: 38\n",
      "\n",
      "Pergunta: What song did Kelly Clarkson perform during the finale?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: What did Clarkson sing during the finale?\n",
      "Resposta Esperada: the coronation song\n",
      "Resposta Gerada: coronation song\n",
      "\n",
      "Pergunta: What was the name of the song?\n",
      "Resposta Esperada: A Moment Like This\n",
      "Resposta Gerada: A Moment Like This\n",
      "\n",
      "Pergunta: Which record did the song break, which was the biggest leap to the top of the Billboard charts?\n",
      "Resposta Esperada: The Beatles\n",
      "Resposta Gerada: Beatles\n",
      "\n",
      "Pergunta: What was the name of the film that the two finalists made together?\n",
      "Resposta Esperada: From Justin to Kelly\n",
      "Resposta Gerada: From Justin to Kelly\n",
      "\n",
      "Pergunta: How many worldwide album sales has Kelly Clarkson had since winning Idol?\n",
      "Resposta Esperada: more than 23 million\n",
      "Resposta Gerada: 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o dataset de amostra SQuAD\n",
    "file_path = 'amostra_squad_1percent.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Verificar a estrutura da amostra carregada\n",
    "print(f\"Chaves do dataset: {squad_data.keys()}\")\n",
    "print(f\"Exemplo de dados: {squad_data['data'][:2]}\")\n",
    "\n",
    "# Carregar o pipeline de Perguntas e Respostas com o modelo BERT\n",
    "nlp = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "# Função para buscar respostas baseadas na consulta\n",
    "def buscar_resposta(pergunta, contexto):\n",
    "    # Limitar o tamanho do contexto (ajustando o tamanho máximo de\n",
    "    #500 caracteres para resposta mais eficiente)\n",
    "    max_contexto_length = 500  # Ajustando para 150 caracteres as respostas ficam incoerentes\n",
    "    if len(contexto) > max_contexto_length:\n",
    "        contexto = contexto[:max_contexto_length]  # Truncando o contexto\n",
    "\n",
    "    # Tentar recuperar a resposta\n",
    "    try:\n",
    "        return nlp(question=pergunta, context=contexto)['answer']\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na geração da resposta: {e}\")\n",
    "        return \"Resposta não disponível\"\n",
    "\n",
    "contador = 0\n",
    "# Testar o modelo com as perguntas extraídas da amostra\n",
    "for artigo in squad_data['data']:\n",
    "    contador += 1\n",
    "\n",
    "    if contador == 5: # executa apenas os 5 primeiros artigos para ficar mais rápido.\n",
    "            break\n",
    "    for qa in artigo['qas']:\n",
    "        \n",
    "        pergunta = qa['question']\n",
    "\n",
    "        # Verificar se a lista 'answers' está vazia antes de acessar\n",
    "        if qa['answers']:\n",
    "            resposta_correta = qa['answers'][0]['text']  # Resposta correta (para comparação)\n",
    "        else:\n",
    "            resposta_correta = \"Não disponível\"\n",
    "\n",
    "        # A chave correta do contexto é 'context', e ele deve ser acessado diretamente aqui\n",
    "        contexto = artigo.get('context', 'Informação não disponível')  # Ajuste para a chave correta de contexto\n",
    "\n",
    "        # Recuperação da resposta\n",
    "        resposta = buscar_resposta(pergunta, contexto)\n",
    "\n",
    "        print(f'Pergunta: {pergunta}\\nResposta Esperada: {resposta_correta}\\nResposta Gerada: {resposta}\\n')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0BRExt_Uaau"
   },
   "source": [
    "# Explicação do Código :\n",
    "Carregamento da Amostra de 1% do Dataset SQuAD:\n",
    "O arquivo amostra_squad_5percent.json é carregado utilizando json.load(). Essa amostra contém 1% dos dados do SQuAD.\n",
    "\n",
    "**Acessando Perguntas e Respostas:**\n",
    "\n",
    "O dataset contém perguntas e respostas dentro de artigos e parágrafos, então estamos acessando essas informações através de squad_data['data'].\n",
    "\n",
    "**Modelo BERT para Perguntas e Respostas:**\n",
    "\n",
    "Usamos o modelo DistilBERT pré-treinado da HuggingFace, adequado para tarefas de perguntas e respostas. A função pipeline(\"question-answering\") permite carregar o modelo facilmente.\n",
    "\n",
    "**Busca de Respostas:**\n",
    "\n",
    "A função buscar_resposta() recebe a pergunta e o contexto (o parágrafo onde a resposta será procurada) e retorna a resposta gerada pelo modelo.\n",
    "\n",
    "**Testando com Perguntas da Amostra:**\n",
    "\n",
    "O código percorre todos os artigos e parágrafos da amostra, fazendo uma pergunta de cada vez e gerando a resposta. A resposta gerada é então impressa no console para que o aluno possa visualizar a qualidade da recuperação de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX7bIUWOFCqf"
   },
   "source": [
    "**Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "- Escolhemos o dataset SQuAD e extraímos uma amostra de 1% para trabalhar com perguntas e respostas reais.\n",
    "\n",
    "- Implementamos um sistema de recuperação de conhecimento assistida, utilizando um modelo de Perguntas e Respostas (QA) baseado em BERT.\n",
    "\n",
    "- Processamos perguntas e respostas, garantindo que o contexto correto fosse passado ao modelo para melhorar a precisão das respostas.\n",
    "\n",
    "- Avaliamos as respostas geradas, comparando-as com as respostas esperadas, identificando pontos de acerto e possíveis melhorias na extração de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxWZe8ljQznA"
   },
   "source": [
    "# AULA 2 - REVISÃO E EXERCÍCIOS PARTE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5Wu96_7wCMv"
   },
   "source": [
    "### Passo a Passo: Solução da Atividade Prática - Exercicio e Revisão parte 2\n",
    "\n",
    "### Implementação de Recuperação de Conhecimento com Fine-Tuning\n",
    "\n",
    "Este notebook tem como objetivo expandir a implementação de recuperação de conhecimento assistida,\n",
    "aplicando frameworks como Hugging Face para desenvolver e testar uma aplicação funcional.\n",
    "\n",
    "### Objetivos:\n",
    "- Explorar a diferença entre modelos pré-treinados e modelos ajustados (fine-tuned);\n",
    "- Aplicar um modelo de IA para responder perguntas baseadas em um dataset;\n",
    "- Comparar a precisão das respostas geradas por diferentes abordagens.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Importando as Bibliotecas Necessárias\n",
    "Primeiro, vamos importar as bibliotecas necessárias para o trabalho com o modelo de perguntas e respostas e para manipulação do dataset:\n",
    "\n",
    " as bibliotecas necessárias para HuggingFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (0.28.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (2.6.0+cpu)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from transformers[torch]) (1.5.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (2.6.0+cpu)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (0.28.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\seduc_sp\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel viana\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826,
     "referenced_widgets": [
      "19796f2cad8a4e17aff7137d903d2d58",
      "9f346295ffee4bc1a3bc305bd65e914e",
      "93229edeec244b0e9b80cf8569379e79",
      "cc7dac90d84f4ecbb67ae9bda2806866",
      "2505bf43c2264b5585db984bc5fd263c",
      "33da6664e9e342f6b2e61436dc7f49a4",
      "5c8fadab8b8d4bef800f2f496bbf5b25",
      "2cb6381951054840ae52ae1d0a40d1e0",
      "056b20b523c949e59b01d101570837ea",
      "a92c6a4df25843adb445f9bd9ad21199",
      "97d48847d9f4484b95c6400e84845888",
      "2ecd6f7de1044a5796056c853ad83cf9",
      "5655d76a1efa4636bec19dfd73fc7caa",
      "32ecd895164d4146ac4bc71923717807",
      "4f1b2ee0c7d74d41b8b547042b29b7a2",
      "ce0c2f642bc641c9baff1c7f4c9278c9",
      "2292442810ca42e0a6fccc4610845c66",
      "09fdc85e80d84eaf8165dbe6d7a84f67",
      "61406756d27d42558d052494019f7fbb",
      "2769e23ed19545a586f6e8d11cb13a78",
      "f4723e46cd0e4ae6a761ff9d3f7cf557",
      "227caf2413f149daa5c43dbaa018892a"
     ]
    },
    "id": "9sUU8LzcpDDO",
    "outputId": "caa8d229-c3df-4066-a030-b0afa450a199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Map: 100%|██████████| 16/16 [00:00<00:00, 1309.39 examples/s]\n",
      "Map: 100%|██████████| 5/5 [00:00<00:00, 569.26 examples/s]\n",
      "C:\\ProgramData\\anaconda3\\envs\\SEDUC_SP\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Daniel Viana\\AppData\\Local\\Temp\\ipykernel_9324\\848344707.py:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.993261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.654542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.301044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pergunta: Which tunnel do 120,000 vehicles travel through a day in NYC?\n",
      "Resposta Verdadeira: The Lincoln Tunnel\n",
      "Resposta do Modelo Ajustado: [CLS]\n",
      "\n",
      "Pergunta: The Holland Tunnel opened in what year?\n",
      "Resposta Verdadeira: 1927\n",
      "Resposta do Modelo Ajustado: 1927\n",
      "\n",
      "Pergunta: The Queens-Midtown Tunnel was finished in what year?\n",
      "Resposta Verdadeira: 1940\n",
      "Resposta do Modelo Ajustado: 1940\n",
      "\n",
      "Pergunta: Who was the first person to drive through The Queens-Midtown Tunnel?\n",
      "Resposta Verdadeira: President Franklin D. Roosevelt\n",
      "Resposta do Modelo Ajustado: President Franklin D. Roosevelt\n",
      "\n",
      "Pergunta: How many vehicles utilize the Lincoln Tunnel daily?\n",
      "Resposta Verdadeira: 120,000\n",
      "Resposta do Modelo Ajustado: 120, 000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Desativar o Weights & Biases (W&B)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\"\"\"\n",
    "## 1. Carregar o Dataset da Aula 1\n",
    "\n",
    "O dataset utilizado contém perguntas e respostas extraídas do conjunto de dados SQuAD.\n",
    "O objetivo é utilizar este dataset para testar a performance dos modelos na tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = \"amostra_squad_1percent.json\"\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\"\"\"\n",
    "## 2. Extração das Perguntas e Contextos\n",
    "\n",
    "O dataset contém perguntas associadas a um contexto. Extrairemos esses pares para alimentar o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def extract_qa_pairs(data):\n",
    "    qa_pairs = []\n",
    "    for item in data[\"data\"]:\n",
    "        context = item[\"context\"]\n",
    "        for qa in item[\"qas\"]:\n",
    "            question = qa[\"question\"]\n",
    "            answer = qa[\"answers\"][0][\"text\"] if qa[\"answers\"] else \"\"\n",
    "            qa_pairs.append((context, question, answer))\n",
    "    return qa_pairs\n",
    "\n",
    "qa_pairs = extract_qa_pairs(data)\n",
    "\n",
    "\"\"\"\n",
    "## 3. Modelo Pré-Treinado\n",
    "\n",
    "Usamos um modelo pré-treinado do Hugging Face (`deepset/bert-base-cased-squad2`)\n",
    "para realizar a tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
    "\n",
    "def hf_answer(question, context):\n",
    "    return qa_pipeline({\"question\": question, \"context\": context})[\"answer\"]\n",
    "\n",
    "\"\"\"\n",
    "## 4. Teste do Modelo Pré-Treinado\n",
    "\n",
    "Selecionamos algumas perguntas do dataset e geramos respostas utilizando o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def test_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        hf_resp = hf_answer(question, context)\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo\": hf_resp\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_results = test_model()\n",
    "\n",
    "\"\"\"\n",
    "## 5. Fine-Tuning do Modelo\n",
    "\n",
    "Aqui treinaremos o modelo `deepset/bert-base-cased-squad2` no dataset específico para melhorar a precisão.\n",
    "\"\"\"\n",
    "\n",
    "# Carregar o modelo e tokenizer\n",
    "model_name = \"deepset/bert-base-cased-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = tokenizer(examples[\"question\"], examples[\"context\"], truncation=True, padding=\"max_length\", max_length=384)\n",
    "    inputs[\"start_positions\"] = [context.find(ans[\"text\"][0]) for context, ans in zip(examples[\"context\"], examples[\"answers\"])]\n",
    "    inputs[\"end_positions\"] = [start + len(ans[\"text\"][0]) for start, ans in zip(inputs[\"start_positions\"], examples[\"answers\"])]\n",
    "    return inputs\n",
    "\n",
    "# Criar um dataset estruturado para fine-tuning\n",
    "dataset_dict = {\"question\": [], \"context\": [], \"answers\": []}\n",
    "for context, question, answer in qa_pairs:\n",
    "    dataset_dict[\"question\"].append(question)\n",
    "    dataset_dict[\"context\"].append(context)\n",
    "    dataset_dict[\"answers\"].append({\"text\": [answer], \"answer_start\": [context.find(answer)]})\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "dataset = dataset.train_test_split(test_size=0.2)  # Separar treino e validação\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Configuração do treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"  # Desativar Weights & Biases\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "\"\"\"\n",
    "## 6. Teste do Modelo Ajustado\n",
    "\n",
    "Após o fine-tuning, testamos o modelo novamente para comparar a performance com o modelo pré-treinado.\n",
    "\"\"\"\n",
    "\n",
    "def test_finetuned_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=384)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo Ajustado\": answer\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_finetuned_results = test_finetuned_model()\n",
    "\n",
    "\"\"\"\n",
    "## 7. Comparação de Resultados\n",
    "\n",
    "Mostramos as respostas geradas pelo modelo pré-treinado e pelo modelo ajustado para analisar diferenças na precisão.\n",
    "\"\"\"\n",
    "\n",
    "for result in test_finetuned_results:\n",
    "    print(\"\\nPergunta:\", result[\"Pergunta\"])\n",
    "    print(\"Resposta Verdadeira:\", result[\"Resposta Verdadeira\"])\n",
    "    print(\"Resposta do Modelo Ajustado:\", result[\"Resposta do Modelo Ajustado\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opRJLw_Tr61s"
   },
   "source": [
    "\n",
    "### **Conclusão da Atividade**\n",
    "\n",
    "### **1. Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "Esta atividade teve como objetivo expandir a implementação de recuperação de conhecimento assistida, utilizando modelos de IA para perguntas e respostas.\n",
    "\n",
    "Foram testadas abordagens com modelos pré-treinados e ajustados (fine-tuned), utilizando o framework Hugging Face e um subconjunto do dataset SQuAD.\n",
    "\n",
    "### **2. Metodologia**\n",
    "\n",
    "A implementação seguiu os seguintes passos:\n",
    "\n",
    "Carregamento do Dataset utilizado também na aula1: O conjunto de dados foi extraído e processado.\n",
    "\n",
    "Aplicação do Modelo Pré-Treinado: Foi utilizado o modelo deepset/bert-base-cased-squad2 para responder perguntas diretamente.\n",
    "\n",
    "Fine-Tuning do Modelo: Ajustamos o modelo com um subconjunto dos dados para melhorar sua precisão.\n",
    "\n",
    "Comparação de Resultados: Avaliamos o desempenho do modelo pré-treinado versus o modelo ajustado.\n",
    "\n",
    "Desativação de Dependências Externas: Garantimos que o código não requer chaves de API nem conexão com o W&B.\n",
    "\n",
    "### **3. Resultados Obtidos**\n",
    "\n",
    "O modelo pré-treinado conseguiu gerar respostas relevantes, mas apresentou limitações em perguntas mais complexas.\n",
    "\n",
    "O modelo ajustado demonstrou melhorias significativas na precisão das respostas, especialmente em perguntas específicas do dataset.\n",
    "\n",
    "O tempo de treinamento foi otimizado ajustando o batch size e o número de épocas.\n",
    "\n",
    "Desativamos o W&B para garantir um ambiente de execução independente.\n",
    "\n",
    "### **4. Dificuldades Encontradas e Soluções**\n",
    "\n",
    "4.1 Pesos não utilizados\n",
    "\n",
    "Problema: Avisos sobre pesos não utilizados ao carregar o modelo.\n",
    "Solução: Garantimos que o modelo correto (deepset/bert-base-cased-squad2) foi utilizado para evitar incompatibilidades.\n",
    "\n",
    "4.2 Falta de Conjunto de Validação\n",
    "\n",
    "Problema: O Trainer exigia um dataset de validação.\n",
    "Solução: Criamos um conjunto de validação separado do dataset de treinamento.\n",
    "\n",
    "4.3 Requisição de Chave de API\n",
    "\n",
    "Problema: O W&B exigia autenticação.\n",
    "Solução: Desativamos o W&B com os.environ[\"WANDB_DISABLED\"] = \"true\" e report_to=\"none\".\n",
    "\n",
    "### **5. Conclusão**\n",
    "\n",
    "A atividade demonstrou a importância do **fine-tuning** para melhorar o desempenho de modelos de perguntas e respostas. O modelo ajustado apresentou respostas mais precisas e contextualizadas, destacando a relevância da adaptação do modelo ao domínio específico. A implementação final permitiu um fluxo de trabalho eficiente e livre de dependências externas, garantindo replicabilidade.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "056b20b523c949e59b01d101570837ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "09fdc85e80d84eaf8165dbe6d7a84f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19796f2cad8a4e17aff7137d903d2d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f346295ffee4bc1a3bc305bd65e914e",
       "IPY_MODEL_93229edeec244b0e9b80cf8569379e79",
       "IPY_MODEL_cc7dac90d84f4ecbb67ae9bda2806866"
      ],
      "layout": "IPY_MODEL_2505bf43c2264b5585db984bc5fd263c"
     }
    },
    "227caf2413f149daa5c43dbaa018892a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2292442810ca42e0a6fccc4610845c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2505bf43c2264b5585db984bc5fd263c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2769e23ed19545a586f6e8d11cb13a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cb6381951054840ae52ae1d0a40d1e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ecd6f7de1044a5796056c853ad83cf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5655d76a1efa4636bec19dfd73fc7caa",
       "IPY_MODEL_32ecd895164d4146ac4bc71923717807",
       "IPY_MODEL_4f1b2ee0c7d74d41b8b547042b29b7a2"
      ],
      "layout": "IPY_MODEL_ce0c2f642bc641c9baff1c7f4c9278c9"
     }
    },
    "32ecd895164d4146ac4bc71923717807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61406756d27d42558d052494019f7fbb",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2769e23ed19545a586f6e8d11cb13a78",
      "value": 3
     }
    },
    "33da6664e9e342f6b2e61436dc7f49a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1b2ee0c7d74d41b8b547042b29b7a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4723e46cd0e4ae6a761ff9d3f7cf557",
      "placeholder": "​",
      "style": "IPY_MODEL_227caf2413f149daa5c43dbaa018892a",
      "value": " 3/3 [00:00&lt;00:00, 72.53 examples/s]"
     }
    },
    "5655d76a1efa4636bec19dfd73fc7caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2292442810ca42e0a6fccc4610845c66",
      "placeholder": "​",
      "style": "IPY_MODEL_09fdc85e80d84eaf8165dbe6d7a84f67",
      "value": "Map: 100%"
     }
    },
    "5c8fadab8b8d4bef800f2f496bbf5b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61406756d27d42558d052494019f7fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93229edeec244b0e9b80cf8569379e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cb6381951054840ae52ae1d0a40d1e0",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_056b20b523c949e59b01d101570837ea",
      "value": 9
     }
    },
    "97d48847d9f4484b95c6400e84845888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f346295ffee4bc1a3bc305bd65e914e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33da6664e9e342f6b2e61436dc7f49a4",
      "placeholder": "​",
      "style": "IPY_MODEL_5c8fadab8b8d4bef800f2f496bbf5b25",
      "value": "Map: 100%"
     }
    },
    "a92c6a4df25843adb445f9bd9ad21199": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7dac90d84f4ecbb67ae9bda2806866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a92c6a4df25843adb445f9bd9ad21199",
      "placeholder": "​",
      "style": "IPY_MODEL_97d48847d9f4484b95c6400e84845888",
      "value": " 9/9 [00:00&lt;00:00, 199.70 examples/s]"
     }
    },
    "ce0c2f642bc641c9baff1c7f4c9278c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4723e46cd0e4ae6a761ff9d3f7cf557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
