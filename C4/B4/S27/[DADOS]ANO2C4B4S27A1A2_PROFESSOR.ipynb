{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8wj4Sf5c2aJ"
   },
   "source": [
    "\n",
    "<h1 style=\"text-align: center;\">CIÊNCIA DE DADOS</h1>\n",
    "<h1 style=\"text-align: center;\">Roteiro de Atividade Prática - PROFESSOR</h1>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsXxX6j-QiT6"
   },
   "source": [
    "# AULA 1 - REVISÃO E EXERCÍCIOS PARTE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAMhvuKRDhyd"
   },
   "source": [
    "### Passo a Passo no código gerado e após o código há uma explicação clara e objetivo de tudo o que foi feito, além do mesmo estar todo comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoIl_gXBVnoW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Carregar o dataset SQuAD (ajustar o caminho conforme necessário)\n",
    "with open('[DADOS]ANO2C4B4S27A1A2_DATASET_train-v2.0.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Exibir a estrutura do dataset\n",
    "print(f\"Estrutura do dataset: {list(squad_data.keys())}\")\n",
    "\n",
    "# Acessar as perguntas e respostas\n",
    "perguntas_respostas = squad_data['data']\n",
    "\n",
    "# Gerar 1% dos dados\n",
    "amostra = []\n",
    "\n",
    "for artigo in perguntas_respostas:\n",
    "    # Selecione 1% aleatório de perguntas de cada artigo para a execução ficar mais rápida\n",
    "    amostra_artigo = random.sample(artigo['paragraphs'], int(0.01 * len(artigo['paragraphs'])))\n",
    "    amostra.extend(amostra_artigo)\n",
    "\n",
    "# Verificar a amostra extraída\n",
    "print(f\"Exemplo de amostra extraída: {amostra[0]}\")\n",
    "\n",
    "# Salvar os 1% extraídos em um novo arquivo\n",
    "with open('amostra_squad_1percent.json', 'w') as f:\n",
    "    json.dump({'data': amostra}, f)\n",
    "\n",
    "print(\"Amostra de 1% do SQuAD gerada e salva com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o4bq5AZpBeE"
   },
   "source": [
    "### Importar e utilizar a amostra gerada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yas2XbpWk4B"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Carregar a amostra de 1% do dataset SQuAD\n",
    "with open('amostra_squad_1percent.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "print(squad_data.keys())\n",
    "# Verificar a estrutura da amostra carregada\n",
    "#print(f\"Exemplo de estrutura do dataset: {squad_data.keys()}\")  # Verificar as principais chaves\n",
    "print(squad_data['data'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm1X29OmDVVk",
    "outputId": "4fe52ae6-10d6-4230-c735-520c04e6eafe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o dataset de amostra SQuAD\n",
    "file_path = 'amostra_squad_1percent.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Verificar a estrutura da amostra carregada\n",
    "print(f\"Chaves do dataset: {squad_data.keys()}\")\n",
    "print(f\"Exemplo de dados: {squad_data['data'][:2]}\")\n",
    "\n",
    "# Carregar o pipeline de Perguntas e Respostas com o modelo BERT\n",
    "nlp = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "# Função para buscar respostas baseadas na consulta\n",
    "def buscar_resposta(pergunta, contexto):\n",
    "    # Limitar o tamanho do contexto (ajustando o tamanho máximo de\n",
    "    #500 caracteres para resposta mais eficiente)\n",
    "    max_contexto_length = 500  # Ajustando para 150 caracteres as respostas ficam incoerentes\n",
    "    if len(contexto) > max_contexto_length:\n",
    "        contexto = contexto[:max_contexto_length]  # Truncando o contexto\n",
    "\n",
    "    # Tentar recuperar a resposta\n",
    "    try:\n",
    "        return nlp(question=pergunta, context=contexto)['answer']\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na geração da resposta: {e}\")\n",
    "        return \"Resposta não disponível\"\n",
    "\n",
    "contador = 0\n",
    "# Testar o modelo com as perguntas extraídas da amostra\n",
    "for artigo in squad_data['data']:\n",
    "    contador += 1\n",
    "\n",
    "    if contador == 5: # executa apenas os 5 primeiros artigos para ficar mais rápido.\n",
    "            break\n",
    "    for qa in artigo['qas']:\n",
    "        \n",
    "        pergunta = qa['question']\n",
    "\n",
    "        # Verificar se a lista 'answers' está vazia antes de acessar\n",
    "        if qa['answers']:\n",
    "            resposta_correta = qa['answers'][0]['text']  # Resposta correta (para comparação)\n",
    "        else:\n",
    "            resposta_correta = \"Não disponível\"\n",
    "\n",
    "        # A chave correta do contexto é 'context', e ele deve ser acessado diretamente aqui\n",
    "        contexto = artigo.get('context', 'Informação não disponível')  # Ajuste para a chave correta de contexto\n",
    "\n",
    "        # Recuperação da resposta\n",
    "        resposta = buscar_resposta(pergunta, contexto)\n",
    "\n",
    "        print(f'Pergunta: {pergunta}\\nResposta Esperada: {resposta_correta}\\nResposta Gerada: {resposta}\\n')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0BRExt_Uaau"
   },
   "source": [
    "# Explicação do Código :\n",
    "Carregamento da Amostra de 1% do Dataset SQuAD:\n",
    "O arquivo amostra_squad_5percent.json é carregado utilizando json.load(). Essa amostra contém 1% dos dados do SQuAD.\n",
    "\n",
    "**Acessando Perguntas e Respostas:**\n",
    "\n",
    "O dataset contém perguntas e respostas dentro de artigos e parágrafos, então estamos acessando essas informações através de squad_data['data'].\n",
    "\n",
    "**Modelo BERT para Perguntas e Respostas:**\n",
    "\n",
    "Usamos o modelo DistilBERT pré-treinado da HuggingFace, adequado para tarefas de perguntas e respostas. A função pipeline(\"question-answering\") permite carregar o modelo facilmente.\n",
    "\n",
    "**Busca de Respostas:**\n",
    "\n",
    "A função buscar_resposta() recebe a pergunta e o contexto (o parágrafo onde a resposta será procurada) e retorna a resposta gerada pelo modelo.\n",
    "\n",
    "**Testando com Perguntas da Amostra:**\n",
    "\n",
    "O código percorre todos os artigos e parágrafos da amostra, fazendo uma pergunta de cada vez e gerando a resposta. A resposta gerada é então impressa no console para que o aluno possa visualizar a qualidade da recuperação de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX7bIUWOFCqf"
   },
   "source": [
    "**Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "- Escolhemos o dataset SQuAD e extraímos uma amostra de 1% para trabalhar com perguntas e respostas reais.\n",
    "\n",
    "- Implementamos um sistema de recuperação de conhecimento assistida, utilizando um modelo de Perguntas e Respostas (QA) baseado em BERT.\n",
    "\n",
    "- Processamos perguntas e respostas, garantindo que o contexto correto fosse passado ao modelo para melhorar a precisão das respostas.\n",
    "\n",
    "- Avaliamos as respostas geradas, comparando-as com as respostas esperadas, identificando pontos de acerto e possíveis melhorias na extração de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxWZe8ljQznA"
   },
   "source": [
    "# AULA 2 - REVISÃO E EXERCÍCIOS PARTE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5Wu96_7wCMv"
   },
   "source": [
    "### Passo a Passo: Solução da Atividade Prática - Exercicio e Revisão parte 2\n",
    "\n",
    "### Implementação de Recuperação de Conhecimento com Fine-Tuning\n",
    "\n",
    "Este notebook tem como objetivo expandir a implementação de recuperação de conhecimento assistida,\n",
    "aplicando frameworks como Hugging Face para desenvolver e testar uma aplicação funcional.\n",
    "\n",
    "### Objetivos:\n",
    "- Explorar a diferença entre modelos pré-treinados e modelos ajustados (fine-tuned);\n",
    "- Aplicar um modelo de IA para responder perguntas baseadas em um dataset;\n",
    "- Comparar a precisão das respostas geradas por diferentes abordagens.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Importando as Bibliotecas Necessárias\n",
    "Primeiro, vamos importar as bibliotecas necessárias para o trabalho com o modelo de perguntas e respostas e para manipulação do dataset:\n",
    "\n",
    " as bibliotecas necessárias para HuggingFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826,
     "referenced_widgets": [
      "19796f2cad8a4e17aff7137d903d2d58",
      "9f346295ffee4bc1a3bc305bd65e914e",
      "93229edeec244b0e9b80cf8569379e79",
      "cc7dac90d84f4ecbb67ae9bda2806866",
      "2505bf43c2264b5585db984bc5fd263c",
      "33da6664e9e342f6b2e61436dc7f49a4",
      "5c8fadab8b8d4bef800f2f496bbf5b25",
      "2cb6381951054840ae52ae1d0a40d1e0",
      "056b20b523c949e59b01d101570837ea",
      "a92c6a4df25843adb445f9bd9ad21199",
      "97d48847d9f4484b95c6400e84845888",
      "2ecd6f7de1044a5796056c853ad83cf9",
      "5655d76a1efa4636bec19dfd73fc7caa",
      "32ecd895164d4146ac4bc71923717807",
      "4f1b2ee0c7d74d41b8b547042b29b7a2",
      "ce0c2f642bc641c9baff1c7f4c9278c9",
      "2292442810ca42e0a6fccc4610845c66",
      "09fdc85e80d84eaf8165dbe6d7a84f67",
      "61406756d27d42558d052494019f7fbb",
      "2769e23ed19545a586f6e8d11cb13a78",
      "f4723e46cd0e4ae6a761ff9d3f7cf557",
      "227caf2413f149daa5c43dbaa018892a"
     ]
    },
    "id": "9sUU8LzcpDDO",
    "outputId": "caa8d229-c3df-4066-a030-b0afa450a199"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Desativar o Weights & Biases (W&B)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\"\"\"\n",
    "## 1. Carregar o Dataset da Aula 1\n",
    "\n",
    "O dataset utilizado contém perguntas e respostas extraídas do conjunto de dados SQuAD.\n",
    "O objetivo é utilizar este dataset para testar a performance dos modelos na tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = \"amostra_squad_1percent.json\"\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\"\"\"\n",
    "## 2. Extração das Perguntas e Contextos\n",
    "\n",
    "O dataset contém perguntas associadas a um contexto. Extrairemos esses pares para alimentar o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def extract_qa_pairs(data):\n",
    "    qa_pairs = []\n",
    "    for item in data[\"data\"]:\n",
    "        context = item[\"context\"]\n",
    "        for qa in item[\"qas\"]:\n",
    "            question = qa[\"question\"]\n",
    "            answer = qa[\"answers\"][0][\"text\"] if qa[\"answers\"] else \"\"\n",
    "            qa_pairs.append((context, question, answer))\n",
    "    return qa_pairs\n",
    "\n",
    "qa_pairs = extract_qa_pairs(data)\n",
    "\n",
    "\"\"\"\n",
    "## 3. Modelo Pré-Treinado\n",
    "\n",
    "Usamos um modelo pré-treinado do Hugging Face (`deepset/bert-base-cased-squad2`)\n",
    "para realizar a tarefa de perguntas e respostas.\n",
    "\"\"\"\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
    "\n",
    "def hf_answer(question, context):\n",
    "    return qa_pipeline({\"question\": question, \"context\": context})[\"answer\"]\n",
    "\n",
    "\"\"\"\n",
    "## 4. Teste do Modelo Pré-Treinado\n",
    "\n",
    "Selecionamos algumas perguntas do dataset e geramos respostas utilizando o modelo.\n",
    "\"\"\"\n",
    "\n",
    "def test_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        hf_resp = hf_answer(question, context)\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo\": hf_resp\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_results = test_model()\n",
    "\n",
    "\"\"\"\n",
    "## 5. Fine-Tuning do Modelo\n",
    "\n",
    "Aqui treinaremos o modelo `deepset/bert-base-cased-squad2` no dataset específico para melhorar a precisão.\n",
    "\"\"\"\n",
    "\n",
    "# Carregar o modelo e tokenizer\n",
    "model_name = \"deepset/bert-base-cased-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = tokenizer(examples[\"question\"], examples[\"context\"], truncation=True, padding=\"max_length\", max_length=384)\n",
    "    inputs[\"start_positions\"] = [context.find(ans[\"text\"][0]) for context, ans in zip(examples[\"context\"], examples[\"answers\"])]\n",
    "    inputs[\"end_positions\"] = [start + len(ans[\"text\"][0]) for start, ans in zip(inputs[\"start_positions\"], examples[\"answers\"])]\n",
    "    return inputs\n",
    "\n",
    "# Criar um dataset estruturado para fine-tuning\n",
    "dataset_dict = {\"question\": [], \"context\": [], \"answers\": []}\n",
    "for context, question, answer in qa_pairs:\n",
    "    dataset_dict[\"question\"].append(question)\n",
    "    dataset_dict[\"context\"].append(context)\n",
    "    dataset_dict[\"answers\"].append({\"text\": [answer], \"answer_start\": [context.find(answer)]})\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "dataset = dataset.train_test_split(test_size=0.2)  # Separar treino e validação\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Configuração do treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"  # Desativar Weights & Biases\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.train()\n",
    "\n",
    "\"\"\"\n",
    "## 6. Teste do Modelo Ajustado\n",
    "\n",
    "Após o fine-tuning, testamos o modelo novamente para comparar a performance com o modelo pré-treinado.\n",
    "\"\"\"\n",
    "\n",
    "def test_finetuned_model():\n",
    "    results = []\n",
    "    for context, question, true_answer in qa_pairs[:5]:\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=384)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "        results.append({\n",
    "            \"Pergunta\": question,\n",
    "            \"Resposta Verdadeira\": true_answer,\n",
    "            \"Resposta do Modelo Ajustado\": answer\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_finetuned_results = test_finetuned_model()\n",
    "\n",
    "\"\"\"\n",
    "## 7. Comparação de Resultados\n",
    "\n",
    "Mostramos as respostas geradas pelo modelo pré-treinado e pelo modelo ajustado para analisar diferenças na precisão.\n",
    "\"\"\"\n",
    "\n",
    "for result in test_finetuned_results:\n",
    "    print(\"\\nPergunta:\", result[\"Pergunta\"])\n",
    "    print(\"Resposta Verdadeira:\", result[\"Resposta Verdadeira\"])\n",
    "    print(\"Resposta do Modelo Ajustado:\", result[\"Resposta do Modelo Ajustado\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opRJLw_Tr61s"
   },
   "source": [
    "\n",
    "### **Conclusão da Atividade**\n",
    "\n",
    "### **1. Resumo do que fizemos nesta atividade:**\n",
    "\n",
    "Esta atividade teve como objetivo expandir a implementação de recuperação de conhecimento assistida, utilizando modelos de IA para perguntas e respostas.\n",
    "\n",
    "Foram testadas abordagens com modelos pré-treinados e ajustados (fine-tuned), utilizando o framework Hugging Face e um subconjunto do dataset SQuAD.\n",
    "\n",
    "### **2. Metodologia**\n",
    "\n",
    "A implementação seguiu os seguintes passos:\n",
    "\n",
    "Carregamento do Dataset utilizado também na aula1: O conjunto de dados foi extraído e processado.\n",
    "\n",
    "Aplicação do Modelo Pré-Treinado: Foi utilizado o modelo deepset/bert-base-cased-squad2 para responder perguntas diretamente.\n",
    "\n",
    "Fine-Tuning do Modelo: Ajustamos o modelo com um subconjunto dos dados para melhorar sua precisão.\n",
    "\n",
    "Comparação de Resultados: Avaliamos o desempenho do modelo pré-treinado versus o modelo ajustado.\n",
    "\n",
    "Desativação de Dependências Externas: Garantimos que o código não requer chaves de API nem conexão com o W&B.\n",
    "\n",
    "### **3. Resultados Obtidos**\n",
    "\n",
    "O modelo pré-treinado conseguiu gerar respostas relevantes, mas apresentou limitações em perguntas mais complexas.\n",
    "\n",
    "O modelo ajustado demonstrou melhorias significativas na precisão das respostas, especialmente em perguntas específicas do dataset.\n",
    "\n",
    "O tempo de treinamento foi otimizado ajustando o batch size e o número de épocas.\n",
    "\n",
    "Desativamos o W&B para garantir um ambiente de execução independente.\n",
    "\n",
    "### **4. Dificuldades Encontradas e Soluções**\n",
    "\n",
    "4.1 Pesos não utilizados\n",
    "\n",
    "Problema: Avisos sobre pesos não utilizados ao carregar o modelo.\n",
    "Solução: Garantimos que o modelo correto (deepset/bert-base-cased-squad2) foi utilizado para evitar incompatibilidades.\n",
    "\n",
    "4.2 Falta de Conjunto de Validação\n",
    "\n",
    "Problema: O Trainer exigia um dataset de validação.\n",
    "Solução: Criamos um conjunto de validação separado do dataset de treinamento.\n",
    "\n",
    "4.3 Requisição de Chave de API\n",
    "\n",
    "Problema: O W&B exigia autenticação.\n",
    "Solução: Desativamos o W&B com os.environ[\"WANDB_DISABLED\"] = \"true\" e report_to=\"none\".\n",
    "\n",
    "### **5. Conclusão**\n",
    "\n",
    "A atividade demonstrou a importância do **fine-tuning** para melhorar o desempenho de modelos de perguntas e respostas. O modelo ajustado apresentou respostas mais precisas e contextualizadas, destacando a relevância da adaptação do modelo ao domínio específico. A implementação final permitiu um fluxo de trabalho eficiente e livre de dependências externas, garantindo replicabilidade.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "056b20b523c949e59b01d101570837ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "09fdc85e80d84eaf8165dbe6d7a84f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19796f2cad8a4e17aff7137d903d2d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f346295ffee4bc1a3bc305bd65e914e",
       "IPY_MODEL_93229edeec244b0e9b80cf8569379e79",
       "IPY_MODEL_cc7dac90d84f4ecbb67ae9bda2806866"
      ],
      "layout": "IPY_MODEL_2505bf43c2264b5585db984bc5fd263c"
     }
    },
    "227caf2413f149daa5c43dbaa018892a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2292442810ca42e0a6fccc4610845c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2505bf43c2264b5585db984bc5fd263c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2769e23ed19545a586f6e8d11cb13a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cb6381951054840ae52ae1d0a40d1e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ecd6f7de1044a5796056c853ad83cf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5655d76a1efa4636bec19dfd73fc7caa",
       "IPY_MODEL_32ecd895164d4146ac4bc71923717807",
       "IPY_MODEL_4f1b2ee0c7d74d41b8b547042b29b7a2"
      ],
      "layout": "IPY_MODEL_ce0c2f642bc641c9baff1c7f4c9278c9"
     }
    },
    "32ecd895164d4146ac4bc71923717807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61406756d27d42558d052494019f7fbb",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2769e23ed19545a586f6e8d11cb13a78",
      "value": 3
     }
    },
    "33da6664e9e342f6b2e61436dc7f49a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1b2ee0c7d74d41b8b547042b29b7a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4723e46cd0e4ae6a761ff9d3f7cf557",
      "placeholder": "​",
      "style": "IPY_MODEL_227caf2413f149daa5c43dbaa018892a",
      "value": " 3/3 [00:00&lt;00:00, 72.53 examples/s]"
     }
    },
    "5655d76a1efa4636bec19dfd73fc7caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2292442810ca42e0a6fccc4610845c66",
      "placeholder": "​",
      "style": "IPY_MODEL_09fdc85e80d84eaf8165dbe6d7a84f67",
      "value": "Map: 100%"
     }
    },
    "5c8fadab8b8d4bef800f2f496bbf5b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61406756d27d42558d052494019f7fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93229edeec244b0e9b80cf8569379e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cb6381951054840ae52ae1d0a40d1e0",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_056b20b523c949e59b01d101570837ea",
      "value": 9
     }
    },
    "97d48847d9f4484b95c6400e84845888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f346295ffee4bc1a3bc305bd65e914e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33da6664e9e342f6b2e61436dc7f49a4",
      "placeholder": "​",
      "style": "IPY_MODEL_5c8fadab8b8d4bef800f2f496bbf5b25",
      "value": "Map: 100%"
     }
    },
    "a92c6a4df25843adb445f9bd9ad21199": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7dac90d84f4ecbb67ae9bda2806866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a92c6a4df25843adb445f9bd9ad21199",
      "placeholder": "​",
      "style": "IPY_MODEL_97d48847d9f4484b95c6400e84845888",
      "value": " 9/9 [00:00&lt;00:00, 199.70 examples/s]"
     }
    },
    "ce0c2f642bc641c9baff1c7f4c9278c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4723e46cd0e4ae6a761ff9d3f7cf557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
